environments:
  tasks: 
    - "reach-v3"
    # - "push-v3" 
    # - "pick-place-v3"
  seeds: [256] # 5 seeds
  

hyperparameters:
  num_envs: 4  # Number of parallel environments for training
  total_steps: 150000
  start_steps: 10000
  max_episode_steps: 400
  batch_size: 256
  eval_interval: 10000
  replay_buffer_size: 1000000
  hidden_dims: [256, 256]
  updates_per_step: 1
  save_init_at_step: 0  # Step at which to save initial weights (W0). 0 = before training starts
  
  # Default Hyperparameters (Base SAC)
  defaults:
    gamma: 0.99
    tau: 0.005
    actor_lr: 0.0003
    critic_lr: 0.0003
    alpha_lr: 0.0003
    init_alpha: 0.2  
    auto_alpha: True

    target_mean_success: 0.8 
    patience: 3            

  # Per-Task Overrides 
  tasks:
    reach-v3:
      init_alpha: 0.2

    push-v3:
      init_alpha: 1.0
      target_entropy_scale: 1.0
      
    pick-place-v3:
      init_alpha: 1.0
      target_mean_success: 0.8

pruning:
  sparsity: 0.8
  # Gradient-based pruning settings (only used when pruning_method="gradient")
  gradient_method: "taylor"  # Options: "taylor", "gradient", "magnitude"
  num_gradient_batches: 100  # Number of batches to accumulate gradients over
  gradient_batch_size: 256   # Batch size for gradient computation